\section{Context}
\label{section:context}

This project is framed in the broad field of \textit{data mining}, of which we already gave a brief introduction in section~\ref{section:introduction}. We will extend that introduction to provide further understanding of the main topics and concepts of the project’s environment.

\subsection{Data mining}

With the continuous increase of computing power, due to the recent advances in software and hardware, the machine learning field, more commonly known as data mining, has arisen. We have already seen that the concept of data mining is broad and covers many aspects of the knowledge discovery process.\\

We have also reviewed what the scale limits are to classic (batch data processing) data mining techniques. Particularly, it is a matter of the amount of information - the size of the datasets - to be analyzed, but also a matter of the rate of this data acquisition. In this respect, stream data mining is the “subfield” that has grown to give an answer to these technical challenges. A more deeper review of this research area is given in the State of the art section~(\ref{section:state-of-the-art}).

\subsection{Privacy}

Privacy is a concept that can be defined as the ability of an individual or group to seclude\footnote{“Seclusion is the act of placing or keeping someone away from other people.” Source: Merriam-Webster online dictionary~\cite{website:merriamSeclusion}} themselves, or information about themselves, and thereby express themselves selectively. It is understood differently depending on the social and cultural background of individuals, but it is, in fact, recognised as one of the most fundamental rights of the human nature. Indeed, the Universal Declaration of Human Rights’ 12th article~\cite{website:humanRights} states that:

\begin{quote}
No one shall be subjected to arbitrary interference with his privacy, family, home or correspondence, nor to attacks upon his honour and reputation. Everyone has the right to the protection of the law against such interference or attacks.
\end{quote}

This such right has, however, been violated and breached continuously ever since information exchange and advanced communication technologies have been developed and its use increased. It did not began with the spread of the Internet, but its adoption has greatly magnified both the ability to breach people’s privacy and the impact these breaches have.

\subsubsection{Privacy leaks consequences}

We are fully aware of the dramatic consequences that information leaks have caused these past years: the PlayStation Network outage which left millions of video gamers without access to that service~\cite{playstation1} or the more recent celebrity intimate photographs leaks~\cite{celebrities}, just to give a couple of examples. Even though they are referred to as IT security breaches, they are, in fact, privacy rights violations, because sensitive personal information was compromised in either situations.\\

Not only rights are breached when privacy is violated. Economical and social consequences are at stake too. For example. identity thefts are performed on a daily basis, thanks to the vast amount of available data about individuals one could easily gather in the web. These theft was estimated to have a cost in the order of billions of dollars, back in 2005~\cite{DisclosureLaws}. Privacy is, therefore, a very serious question we have to bear in mind.

\subsubsection{Legal framework}

Efforts are being carried out to develop legal frameworks to help protect people’s privacy, at many levels. One such example is the spanish LOPD\footnote{LOPD stands for \textit{Ley Orgánica de Protección de Datos}, a law that was approved by the spanish courts in 1999. It has been modified several times, being the law enforcement regulation approved in 2007.}~\cite{lopd}, a law that aims, among other things, to define different data privacy levels and mandatory proceedings associated to each - no matter the medium used to transfer it or store it.\\

There are some pitfalls to these legislative efforts, though. Firstly, it is really hard to assess their accomplishment in the IT sector and, thus, it is sometimes a matter of confidence in the developer’s good practice. Another important drawback is that online services, such as social networks, can be accessed globally, but, on the other hand, their legislative framework is that of the country to which the backing company offering the service belongs to - jurisdiction definition in the Internet is still a matter of intense debate, nowadays.

\subsubsection{Privacy and data mining}

Within the field of data mining, sensitive data must be treated accordingly, and that involves not only good IT security practices, but a responsible treatment when research results are published.\\

Statistical Disclosure Control (SDC) is the name that the statistical community has given to what the data mining community calls Privacy-Preserving Data Mining (PPDM). This field, whatever its preferred name is, deals with controlling the that information about specific individuals is not extracted from statistical summary results. Also, if full datasets are to be released, PPDM practices should be applied to data in order to preserve privacy, whilst maintaining the statistical significance of it, i. e., the amount of information - knowledge - that this data can provide.\\

Further details of SDC methods and approaches can be found on the State of the art section~(section~\ref{section:state-of-the-art}).

\subsection{Involved stakeholders}

A good way to investigate the motivation driving this project is to examine which third parties are (indirectly, perhaps) involved in this project, giving a general overview of their different possible interests in this work.

\subsubsection{Users: organizations and developers}

The most direct users of the results of this project will be developers - data scientists\footnote{The term \textit{data scientist} is used to designate the evolution of data analysts or business analysts job titles in the world of \textit{Big Data} or data mining. They are trained in computer science and applications, modeling, statistics, analytics and math.
} -, researchers and the companies and organizations that employ them. Using privacy preserving filters, which they don’t need to develop themselves, they are allowed to release their results or their data without compromising their user’s privacy.\\

National statistical agencies\footnote{The ONS (Office for National Statistics, in the UK) team is using statistical disclosure control methods as part of their process methodology~\cite{website:sdc}.} are often bound to use these methods, by law, but that might not be the case with private organizations. In the first place, information is the key to many companies’ success, so they are prone to release it anyway, but there might be many organizations (research centres, academic groups, etc.) that find this possibility interesting or even needful.\\

\textbf{Open Data community:} the still young and poorly extended (and implemented) concept of \textit{open data} can benefit too from the fact that releasing data is no longer a problem in terms of information security. The idea behind this expression is that data sets should not or need not be stored redundantly - if it was easily accessible (through web services, for example), one could exploit diverse data sources without having to gather it himself. Open data platforms exist, in fact, but their contents are poor, at the knowledge discovery level, and are difficult to integrate into data mining systems due to the lack of standard formats, for example.\\

If data sets are more easily anonymized using such privacy preserving methods, they are more likely to be published, aiding open data to fulfill its goals.

\subsubsection{End users: data providers}

When talking about \textit{end users} here, we are referring to everyone that is allowing data be generated from them, gathered, collected, stored and analyzed. Nowadays, this is basically most of the population.\\

End users get the most important benefit from privacy preserving data mining: their data is secure against information disclosure attacks. Because all kinds of sensitive data are kept and analyzed, this turns to be the main motivation for the project. Even though end users might not be aware of the specific technologies that keep their data safe, they still have the right to demand this protection.

\subsection{State of the art}
\label{section:state-of-the-art}

Let’s cover now the latest advancements and discoveries in the different related fields that affect this project.

\subsubsection{Stream mining}

Data stream mining is a relatively new field. Even though its theoretical foundation is based in well-established statistical and computational approaches, it has not been until recent years that this research area has experimented a great growth in interest.\\

The main problem when dealing with streaming data is the high throughput of data being analyzed, under computational resources constraints. Variable data rates is another problem that has to be addressed too. Once these problems are resolved, efforts are done so the same kind of data mining analysis as in the case of batch data processing are available: classification, regression or clustering tasks, as well as outlier detection and recommendation systems. We will not cover these techniques here, because they are not related to this project, by themselves. Instead, we will have a look at some different stream mining solutions, because their working principles do affect the way the project’s algorithms will be implemented.\\

Solutions provided in this field can be categorized into \textit{data-based} and \textit{task-based} ones~\cite{miningDataStreams}, depending on their approach.

\begin{itemize}
	\item \textbf{Data-based stream mining solutions:}
	The idea behind these solutions is to use a subset of the original dataset to perform the required analyses. Diverse techniques that have been used in this sense can further be split into two more categories:
	\begin{itemize}
		 \item \textit{Sampling methods:} either by randomly picking samples of the data stream or by randomly selecting chunks (subsets) of the stream, sampling methods discard part of the incoming data, while performing the knowledge discovery processes with the sampled data. The main problem with this approach is that is hard to know when to pick a sample or which records should be stored, because there is no previous knowledge of the dataset size or its information structure.
		 
		 \item \textit{Summarizing methods:} they use aggregated data or calculated statistical measures (that are continuously recalculated) to provide the information needed for the data mining algorithms. In this case, it is the loss of information and accuracy and the inability to control data distribution fluctuations what renders these methods not so usable as it was desired.
	\end{itemize}
	
	\item \textbf{Task-based stream mining solutions:}
	The solutions that fall into this category are based not on performing data transformations, but on changing the data mining methods to enable their use on data streams.
	\begin{itemize}
		\item \textit{Approximation algorithms:} these are a kind of algorithms that are designed to solve computationally hard problems, by giving an approximate result. Instead of computing exact solutions, they just guarantee a certain error bound. The problem with these methods is, again, the high received data throughput, which they cannot cope as well. Additional tooling is therefore needed if one wishes to use them.
		
		\item \textit{Sliding window method:} this method, a common pattern in many online\footnote{In computer science, an \textit{online algorithm} is one that can process its input piece-by-piece in a serial fashion, i.e., in the order that the input is fed to the algorithm, without having the entire input available from the start.} applications, maintains a \textit{sliding window} in which the most recent data is kept. As data is received from the incoming streams, this window “advances” so new observations are kept inside. The data mining analyses are then performed using the data available inside the window and summarized versions of the older records, in the form of statistical measures or aggregated data.
		This particular method is the one that the MOA package uses - thus its name: Massive \textbf{Online} Analysis. This solution scheme enables dealing with concept drift, which would not be possible if just aggregated data was used.
		
		\item \textit{Algorithm output granularity:} this method is a resource-aware data analysis approach that can perform the local analysis on resource constrained devices, by adapting to resource availability and data stream rates - when resources are completely running out, the results are merged and stored.
	\end{itemize}
\end{itemize}

\textbf{Data stream mining software:} because it is an incipient field, stream mining software packages are quite uncommon. Even though specific applications have been developed~\cite{mineFleet}, MOA remains as one of the few generic\footnote{MOA is not focused towards any particular application scenario: it is a base tool with which we can build such specific systems.}, free and open sourced systems.
In relation to MOA, a new project called SAMOA~\cite{samoa} is being developed too, based on top of MOA itself, and a couple of streaming processing engines: Apache S4~\cite{apacheS4} and Apache Storm~\cite{apacheStorm}, developed by the Apache Software Foundation.

\subsubsection{Privacy preserving stream mining}

Many different methods have been developed to help prevent information disclosure when data mining datasets or results are released. These algorithms pursue the generation of results or data that have particular properties concerning privacy preservation.\\

\textbf{Privacy preserved data properties:} some of the desirable properties of privacy-protected data are:
\begin{itemize}
	\item First described in 2002, by Latanya Sweeney, a release of data is said to have the \textit{$k$-anonymity} property if the information for each person contained in the release cannot be distinguished from at least $k-1$ individuals whose information also appears in the release~\cite{kAnon}.
	
	\item The evolution of the concept of $k$-anonymity is \textit{$l$-diversity} and adds further privacy preservation by adding intra-group diversity, so to avoid the flaws of the $k$-anonymity privacy model~\cite{lDiversity}.
	
	\item Further on, the \textit{$t$-closeness} property definition adds attribute-based privacy enforcement to the $l$-diversity model: to better preserve privacy, all values (all observations) from a particular attribute must not be too much different - instead, they should be close up to a certain threshold~\cite{tCloseness}. This is needed to preserve the privacy of those records that are more easily identifiable because their attribute values are more distinguishable.
\end{itemize}

\textbf{Privacy preserving algorithms:} the algorithms being used nowadays to achieve effective privacy preserving properties to datasets can be categorized into the following groups~\cite{book:StatisticalDisclosureControl}:
\begin{itemize}
	\item \textit{Non-perturbative data masking:} these kind of methods do not perform data values transformations. Instead, they are based in partial suppressions of records or reductions of detail of the datasets. Some examples\footnote{We can’t cover every algorithm in detail, because some of them are not relevant and because those which are to be implemented in this project will be described in detail in the final project report.} are:
	\begin{itemize}
		\item Sampling
		\item Global recoding
		\item Top and bottom coding
		\item Local suppression
	\end{itemize}
	
	\item \textit{Perturbative data masking:} these methods do release the whole dataset, if required, but it is perturbed, this is, values are changed by adding them noise. This way, records are diffused and reidentifying individuals is harder. Some examples are:
	\begin{itemize}
		\item Noise masking
		\item Micro-aggregation
		\item Rank swapping
		\item Data shuffling
		\item Rounding
		\item Re-sampling
		\item PRAM
		\item MASSC
	\end{itemize}
\end{itemize}

\textbf{Privacy preserving \textit{Stream} Mining:} many of the previously listed methods are already implemented in many classical data mining frameworks and software systems; for example, the \texttt{sdcMicro} package for the \textbf{R} statistical package~\cite{sdcMicro}. However, privacy preserving methods are still not widespread in the stream mining ecosystem - that is another motivation for this project.

\subsection{Environmental impact}

No relevant direct environmental impact is related to this project, neither tied to its development nor its further deployment. No use of massive resources is done and the results of the work will not, presumably, result in a significant environmental change of any kind.\\

It is still true, however, that data mining, as a discipline and its broad use, does consume a lot of resources, in terms of technological infrastructure and energy. We cannot forget that collecting, storing and processing data at the industry scale needs entire data centers fully dedicated to the data mining process. Power consumption is a big concern with nowadays information technology, as it is the huge amount of rare materials that electronic devices contain. These are derived or indirect effects of the data mining process. This issue deserves to be examined more closely, in the project’s final report.

\subsection{Social impact}

Concerning social impact, this project’s strength is related to users privacy preservation through the implementation of algorithms that help anonymize their data within the data mining process. This topic will be explained more extensively in the project’s final report, but it is of paramount importance nowadays. Privacy is being relegated to the background with the advent of new information technologies, devices or platforms such as social networks or banking applications. Data is gathered from everyone and there is an increasing need of methods to protect it. Together with other fields more focused in securing the access to data, privacy-preserving data mining is designed to keep data safe at the analysis stage of the data mining process.\\

Not only ethical concerns are addressed by protecting the users’ privacy, but economical issues too. Industrial-scale information theft has a huge impact on enterprise economies, because of distrust and because disclosed sensitive data can be used to make profit of it.
