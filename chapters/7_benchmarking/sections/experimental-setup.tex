\section{Experimental setup}
\label{Benchmarking:Experimental}

A simple experimental setup has been used to assess the performance of the MOA privacy filters in terms of \textit{disclosure risk} and \textit{information loss}. To do so, a MOA \textit{task}\footnote{Within the MOA framework, tasks define a procedure to run as the main program, like a classifier or regression learning task.} was specifically designed to retrieve the results of the evaluation measures of the filters.

\subsection{MOA generators}
\label{Benchmarking:Experimental:MOAGenerators}

In order to test the filters, streams of synthetically generated data have been used, rather than actual datasets, mainly because, this way, we avoid the complex and time consuming preprocessing of real datasets.

The MOA framework offers a rich set of stream data generators, of which we chose the \texttt{RandomRBFGenerator} and the \texttt{WaveformGenerator}. Both streams consist of numerical variables only. Even though most of the implemented filters are capable of dealing with heterogeneous data, some previous tests had shown that the information loss evaluation, based on the $SSE$ estimation, pondered too much categorical attributes differences, thus getting disturbed IL measurements.

The \texttt{RandomRBFGenerator} outputs a stream of 10 attributes and 1 class variable, drawing values for those attributes from radial basis functions (RBFs). The class variable is indeed a categorical one, indicating to which RBF an instance belongs, this is, the intended machine learning task of this generator is \textit{classification}.

The \texttt{WaveformGenerator} generates values by combining two or three base wave functions, which form a numerical stream of 21 attributes and 1 class variable. The machine learning task intended for this generator is, again, \textit{classification}.

\subsection{Experimental design}
\label{Benchmarking:Experimental:Design}

The experiments undertaken during the benchmarking stage of the project consist in generating streams of synthetic data and pipe those streams through each of the privacy filters, for each of the parameters permutations that we decided, taking 100000 instances from the generators. A summary of paramaters values used in those experiments is shown in~\tref{table:filter-params-execution}.

\begin{table}[H]
	\centering
	\begin{tabular}{@{}llll@{}}
		\toprule
		& \multicolumn{3}{c}{\textbf{Parameters}} \\ \cmidrule{2-4}
		\textbf{Privacy filter} & \small\textbf{Name} & \small\textbf{Range} & \small\textbf{Selected values} \\ \midrule
		
		\footnotesize\texttt{NoiseAdditionFilter} & $a$ & $[0,1] \in \mathbb{R}$ & 0.1, 0.25, 0.5, 0.75, 1.0 \\
		& $c$ & $[0,1] \in \mathbb{R}$ & 0.0 \\
		&&&\\
		\footnotesize\texttt{MicroAggregationFilter} & $b$ & $\mathbb{N}^+$ & 100, 250, 500, 1000 \\
		& $k$ & $\mathbb{N}^+,~k \leq b$ & 3, 5, 10, 15, 20, 25, 50, 100 \\
		&&&\\
		\footnotesize\texttt{RankSwappingFilter} & $b$ & $\mathbb{N}^+$ & 100, 250, 500, 1000 \\
		& $p$ & $[1,100] \in \mathbb{N}^+$ & 10, 25, 50, 75, 80 \\
		&&&\\	
		\footnotesize\texttt{DifferentialPrivacyFilter} & $b$ & $\mathbb{N}^+$ & 100, 250, 500, 1000 \\
		& $k$ & $\mathbb{N}^+,~k \leq b$ & 3, 5, 10, 15, 20, 25, 50, 100 \\
		& $\varepsilon$ & $\mathbb{R}^+$ & 0.01, 0.1, 1, 10, 100 \\
		
		\bottomrule
	\end{tabular}
	\caption[Privacy filters benchmark parameterization.]{Privacy filters benchmark parameterization.}
	\label{table:filter-params-execution}
\end{table}

The optimal situation would have been to execute each filter configuration (each parameters permutation) a number of times, in order to statistically validate the results. However, due to the lack of time and resources available, a single execution of each filter was performed during the benchmark phase.

\subsection{Hardware}
\label{Benchmarking:Experimental:Hardware}

The executions of the filters were executed in the following hardware environment\footnote{Only the relevant specifications to the execution of the filters are included.}:

\begin{table}[H]
	\centering
	\begin{tabular}{@{}lll@{}}
		\toprule
		\textbf{Category} & \multicolumn{2}{l}{\textbf{Description}} \\ \midrule
		
		\textbf{Computer model} & \multicolumn{2}{l}{Asus k53-SV} \\
		&&\\
		\textbf{CPU} & Model & Intel(R) Core(TM) i5-2430M, 64 bit \\
		             & Frequency & 2.40GHz \\
		             & Cores & 2 (4 \textit{virtual} threads available) \\
		             & Cache & 32KB data L1 \\
		             &       & 32KB instructions L1 \\
		             &       & 256KB L2 per core \\
		             &       & 3072KB shared L3 \\
		&&\\
		\textbf{Memory} & Capacity & 8GB \\
		                & Frequency & 1333MHz \\
		\bottomrule
	\end{tabular}
	\caption[Hardware benchamark setting.]{Hardware benchamark setting.}
	\label{table:execution-hardware}
\end{table}

\subsection{Software}
\label{Benchmarking:Experimental:Software}

The following software was involved in the execution of the privacy filters benchmarks:

\begin{itemize}
\item \textbf{Operating System:} Ubuntu 12.04 LTS with the Linux kernel 3.2.0-80 version
\item \textbf{Java:} Java 1.7.0\_75 (OpenJDK Runtime Environment, version IcedTea 2.5.4)
\item \textbf{Python:} Python 2.7 (to execute the scripts running the actual MOA tasks)
\end{itemize}